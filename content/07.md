#负载均衡基础
负载均衡是指将应用要处理的负载分散到若干的分立系统，借此来提高应用处理请求的整体能力。负载均衡意味着将处理系统请求的部分工作，交给另一台能同时处理任务的独立系统。它会将一台服务器的负载分发给一组其他的设备。它的优势在于能够降低接收系统请求的主服务器的工作量，从而允许它处理更多的请求并提高处理性能——因为争夺系统资源的概率会降低，并且有更多的机器来处理整个负载。

通常，系统会部分负载均衡，比如将数据库服务器和Web服务器分立就是负载均衡的一种。这是传统负载均衡的典型例子：增加额外的服务器来分担复杂请求的负载。这也是前面这个例子的优势所在。

当最开始的那台Web/数据库服务器到了再增加额外请求，就会拖慢其他请求的处理速度时，你就需要进行扩展了。这能大幅提升数据库和Web服务器的性能，因为它们不再需要争夺CPU时间来处理各自的请求。将处理请求的不同应用分别安装在分立的服务器上只是我们迈出的第一步，还有其他很多种方法可以提高分发和处理负载的能力——但万变不离其宗，根本的目的都是要提高效率和性能。

##负载均衡实战
负载均衡的主要实现途径如下所述：

（1）将应用划分到若干服务器上，通过这些服务器来进行负载均衡。

（2）给应用增加特定的模块来平衡每块应用功能所需要的计算量；例如缓存常见的网站数据，从而节省从硬盘上读取数据的时间，或从数据库内容中产生这些数据的时间，等等。

（3）创建额外的服务器来共享负载；它能有效增加服务器上完成任务所需的计算能力。

##指导原则
负载均衡跟所有形式的系统改动一样，需要一系列指导原则来指导你要完成的大部分工作。理解这些原则对于成功对系统进行负载均衡至关重要，并且能让维护和进一步改进负载均衡及提高系统性能变得相对容易。

- 深入理解系统。深入理解你的系统就是要了解系统如何完成每天的业务工作。
- 规划。规划构建在原则一种简单提到的内容之上，与原则一“阴阳互补”。也就是说，如果缺乏信息，规划就没有什么实际意义，而没有规划，信息也无法起作用。规划意味着设立一个目标，然后完成期望达到的指标，以及寻找各种途径来实现目标。
- 监测和测试。对任何测试过的改动都要进一步监测。作为对系统的了解的一部分，你需要监测并了解建立连接需要多久，或者期望的负载是多少。然后再将这部分内容加到测试中，保证所做的改动产生的结果都是有益的。